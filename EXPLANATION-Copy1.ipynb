{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tensorflow.keras import backend as K\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folder data images\n",
    "\n",
    "root_dir = './images/'\n",
    "img_files_paths = list()\n",
    "class_labels = list()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            rel_dir = os.path.relpath(dir_, root_dir)\n",
    "            class_labels.append(rel_dir)\n",
    "            rel_file = os.path.join(rel_dir, file_name)\n",
    "            rel_file = os.path.join(root_dir, rel_file)\n",
    "            img_files_paths.append(rel_file.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folder data images\n",
    "\n",
    "root_dir1 = './unknown_DB865/'\n",
    "root_dir2 = './unknown_DB866/'\n",
    "img_files_paths_unknown = list()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir1):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            #rel_dir = os.path.relpath(dir_, root_dir1)\n",
    "            #rel_file = os.path.join(rel_dir, file_name)\n",
    "            rel_file = os.path.join(root_dir1, file_name)\n",
    "            img_files_paths_unknown.append(rel_file.replace(\"\\\\\", \"/\"))\n",
    "            \n",
    "for dir_, _, files in os.walk(root_dir2):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            #rel_dir = os.path.relpath(dir_, root_dir2)\n",
    "            #rel_file = os.path.join(rel_dir, file_name)\n",
    "            rel_file = os.path.join(root_dir2, file_name)\n",
    "            img_files_paths_unknown.append(rel_file.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = 'pseudo-vs-all' #  all | pseudo-vs-all | genres\n",
    "\n",
    "if class_type == 'pseudo-vs-all':\n",
    "    class_labels = [l if l == 'pseudoracemus' else 'other' for l in class_labels]\n",
    "elif class_type == 'genres':\n",
    "    class_labels = [l if l != 'pseudoracemus' else 'racemus' for l in class_labels]\n",
    "elif class_type == 'all':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ PARAMETERS ################\n",
    "\n",
    "hidden_vgg = 128\n",
    "#hidden_comb = 64\n",
    "dropout = True\n",
    "#lr_coeff = 3\n",
    "\n",
    "lr_coeff = 5\n",
    "learning_rate = 10 / (10 ** lr_coeff)\n",
    "reg = 'l2'\n",
    "\n",
    "k_folds = 4\n",
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "n_steps = 5\n",
    "n_classes = 2\n",
    "num_struct = 6\n",
    "rs = 42\n",
    "num_replica = 1\n",
    "cweights = 'yes' #no\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import structure list and reorder as img_files_paths\n",
    "struct_df = pd.read_csv('./Categories.csv', sep = ';')\n",
    "struct_unknown_df = pd.read_csv('./Categories_unknown.csv', sep = ';')\n",
    "file_name_list = [path.split('/')[-1] for path in img_files_paths]\n",
    "filename_df = pd.DataFrame(file_name_list)\n",
    "filename_df['img_path'] = img_files_paths\n",
    "filename_df['class'] = class_labels\n",
    "filename_df.columns = ['filename', 'img_path', 'class']\n",
    "\n",
    "full_ohe_df = pd.merge(filename_df, struct_df, on='filename')\n",
    "file_name_list = [path.split('/')[-1] for path in img_files_paths_unknown]\n",
    "filename_df = pd.DataFrame(file_name_list)\n",
    "filename_df['img_path'] = img_files_paths_unknown\n",
    "filename_df.columns = ['filename', 'img_path']\n",
    "\n",
    "unknown_df = pd.merge(filename_df, struct_unknown_df, on='filename')\n",
    "class_ohe = pd.get_dummies(full_ohe_df['class'])\n",
    "full_ohe_df = pd.concat([full_ohe_df, class_ohe],axis=1)\n",
    "full_ohe_df = full_ohe_df.drop(columns=['filename', 'trueclass', 'class'])\n",
    "unknown_df = unknown_df.drop(columns=['filename', 'trueclass'])\n",
    "for i in list(full_ohe_df.columns[-n_classes:]):\n",
    "    unknown_df[i] = [0]*len(unknown_df)\n",
    "full_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = []\n",
    "class_weight = dict()\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_weight[c] = (1 / np.sum(full_ohe_df.iloc[:,-(n_classes-c)].values)) * (len(full_ohe_df) / n_classes)\n",
    "    #weights.append()\n",
    "\n",
    "#class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([img_files_paths, class_labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './Results/IIFINAL_class-{}+struct_hn-{}_epochs-{}_lr-{}_{}_3rep/'.format(n_classes, hidden_vgg, n_epochs, lr_coeff, cweights)\n",
    "\n",
    "loaded_models = []\n",
    "test_dfs = []\n",
    "train_dfs = []\n",
    "predicts = []\n",
    "predicts_train = []\n",
    "\n",
    "xs = []\n",
    "\n",
    "for cvnum in range(1,5):\n",
    "    # load json and create model\n",
    "    json_file = open(save_dir + 'cv'+str(cvnum)+'model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(save_dir +\"cv\"+str(cvnum)+\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    loaded_models.append(loaded_model)\n",
    "    \n",
    "    with open(save_dir +'cv'+str(cvnum)+'_test_files.pickle', 'rb') as f:\n",
    "        filenames= pickle.load(f)\n",
    "\n",
    "    dfc = df.copy()\n",
    "    \n",
    "    test_df = filenames\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       rescale=1./255,\n",
    "                                       rotation_range=10,\n",
    "                                       brightness_range=[0.5,1.8],\n",
    "                                       zoom_range=[0.7,1],\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode=\"reflect\")\n",
    "\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(test_df, x_col='img_path', \n",
    "                                                      y_col=test_df.columns[1:].tolist(),\n",
    "                                                      target_size = (224, 224),\n",
    "                                                      class_mode ='raw',\n",
    "                                                      batch_size = 1,\n",
    "                                                      shuffle = False) \n",
    "    unknown_generator = test_datagen.flow_from_dataframe(unknown_df, x_col='img_path', \n",
    "                                                      y_col=test_df.columns[1:].tolist(),\n",
    "                                                      target_size = (224, 224),\n",
    "                                                      class_mode ='raw',\n",
    "                                                      batch_size = 1,\n",
    "                                                      shuffle = False) \n",
    "    \n",
    "    test_generator.reset()\n",
    "    test_prob = loaded_model.predict_generator(own_test_generator_func(), steps=test_df.shape[0])\n",
    "    #with open(save_dir + 'cv{}_test-prob.pickle'.format(cvnum), 'rb') as handle:\n",
    "    #    test_prob = pickle.load(handle)\n",
    "\n",
    "    #unknown_prob = model.predict_generator(own_test_generator_func_unknown(), steps=unknown_df.shape[0])\n",
    "    with open(save_dir + 'cv{}_unknown-prob.pickle'.format(cvnum), 'rb') as handle:\n",
    "        unknown_prob = pickle.load(handle)\n",
    "    \n",
    "    #predict = loaded_model.predict(test_generator,len(test_generator.filenames))\n",
    "    #predict_train = loaded_model.predict(train_generator,len(train_generator.filenames))\n",
    "    #predicts_train.append(predict_train)\n",
    "    predicts.append(test_prob)\n",
    "    trues = []\n",
    "    for x in test_prob:\n",
    "        trues.append(test_df.columns[7+(list(x).index(max(x)))])\n",
    "    test_df['preds']=np.array(trues)\n",
    "    test_df['true']=test_df.iloc[:,7:7+n_classes].idxmax(1)\n",
    "    test_dfs.append(test_df)\n",
    "    \n",
    "    #train_df['true']=train_generator.classes\n",
    "    #train_df['preds']=np.array(trues_train)\n",
    "    #train_dfs.append(train_df)\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(test_generator.filenames)):\n",
    "        x.append(test_generator.next()[0])\n",
    "        \n",
    "    xs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':22})\n",
    "save_dir = './Results/IIFINAL_class-{}+struct_hn-{}_epochs-{}_lr-{}_{}_3rep/'.format(n_classes, hidden_vgg, n_epochs, lr_coeff, cweights)\n",
    "\n",
    "xs = []\n",
    "\n",
    "for cvnum in range(1,5):\n",
    "    # load json and create model\n",
    "    json_file = open(save_dir + 'cv'+str(cvnum)+'model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(save_dir +\"cv\"+str(cvnum)+\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    #loaded_models.append(loaded_model)\n",
    "    \n",
    "    with open(save_dir +'cv'+str(cvnum)+'_test_files.pickle', 'rb') as f:\n",
    "        filenames= pickle.load(f)\n",
    "\n",
    "    dfc = df.copy()\n",
    "    test_probs = []\n",
    "    test_df = pd.DataFrame()\n",
    "    \n",
    "    for ff in range(len(filenames)):\n",
    "    #for ff in range(3):\n",
    "        test_dff = pd.DataFrame(filenames.iloc[ff,:]).T\n",
    "        test_df = pd.concat([test_df, test_dff], axis = 0)\n",
    "    \n",
    "        train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                           rescale=1./255,\n",
    "                                           rotation_range=10,\n",
    "                                           brightness_range=[0.5,1.8],\n",
    "                                           zoom_range=[0.7,1],\n",
    "                                           horizontal_flip=True,\n",
    "                                           fill_mode=\"reflect\")\n",
    "\n",
    "        test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "\n",
    "        test_generator = test_datagen.flow_from_dataframe(test_dff, x_col='img_path', \n",
    "                                                          y_col=test_df.columns[1:].tolist(),\n",
    "                                                          target_size = (224, 224),\n",
    "                                                          class_mode ='raw',\n",
    "                                                          batch_size = 1,\n",
    "                                                          shuffle = False) \n",
    "        unknown_generator = test_datagen.flow_from_dataframe(unknown_df, x_col='img_path', \n",
    "                                                          y_col=test_df.columns[1:].tolist(),\n",
    "                                                          target_size = (224, 224),\n",
    "                                                          class_mode ='raw',\n",
    "                                                          batch_size = 1,\n",
    "                                                          shuffle = False) \n",
    "    \n",
    "        test_generator.reset()\n",
    "        data = test_generator.next()\n",
    "        imgs = data[0]\n",
    "        meta = data[1][:,:num_struct]\n",
    "        targets = data[1][:,-1*n_classes:]\n",
    "        n_samples = 100\n",
    "        \n",
    "        \n",
    "        def get_classifier_fn(ximgs):\n",
    "            return loaded_model.predict([ximgs.astype('float32'), meta.astype('float32')])\n",
    "        \n",
    "        \n",
    "        #fig = plt.figure(figsize = (15,10))\n",
    "        fig, axs = plt.subplots(n_classes, 3, figsize = (24,20))\n",
    "        fig.suptitle(\"ID \"+test_dfs[cvnum-1].iloc[ff,0].split(\"/\")[3].split(\".\")[0]+\" CLASS = \"+test_dfs[cvnum-1].true.values[ff])\n",
    "        #row, colums = n_classes, 3\n",
    "        ################\n",
    "        #LIME\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        #ximgs = imgs[0].astype('double')\n",
    "        explanation = explainer.explain_instance(imgs[0].astype('double'), \n",
    "                                             get_classifier_fn, \n",
    "                                             top_labels=n_classes, \n",
    "                                             hide_color=None,\n",
    "                                             batch_size=1,\n",
    "                                             num_samples=n_samples)\n",
    "        \n",
    "        #SALIENCY\n",
    "        replace2linear = ReplaceToLinear()\n",
    "        xstensor = tf.convert_to_tensor(imgs[0], dtype=tf.float32)\n",
    "        metatensor = tf.convert_to_tensor(meta.reshape((1,6)), dtype=tf.float32)\n",
    "        # Create Saliency object.\n",
    "        saliency = Saliency(loaded_model,\n",
    "                            model_modifier=replace2linear,\n",
    "                            clone=True)\n",
    "        \n",
    "        #GRADCAM\n",
    "        #create submodel (no meta info)\n",
    "        sub_model = tf.keras.Sequential()\n",
    "        for layer in loaded_model.layers[:20]:\n",
    "            sub_model.add(layer)\n",
    "        example_input_shape = (1, 224, 224, 3)\n",
    "        sub_model.build(example_input_shape)\n",
    "        gradcam = Gradcam(sub_model,\n",
    "                  model_modifier=replace2linear,\n",
    "                  clone=True)\n",
    "        \n",
    "        ##################\n",
    "        for i in range(n_classes):\n",
    "            #LIME\n",
    "            #plt.subplot(row, colums, cnt)\n",
    "            axs[i,0].set_title(\" prob(\"+test_dfs[cvnum-1].columns[7+i]+\") = \"+ str(round(predicts[cvnum-1][ff][i]*100,1))+\"%\")\n",
    "            temp, mask = explanation.get_image_and_mask(explanation.top_labels[i], \n",
    "                                                        negative_only=False, \n",
    "                                                        positive_only=False, \n",
    "                                                        num_features=10, \n",
    "                                                        hide_rest=False)\n",
    "            im0 = axs[i,0].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "            axs[i,0].axis('off')\n",
    "\n",
    "            \n",
    "            #SALIENCY\n",
    "            score = CategoricalScore(i)\n",
    "            saliency_map = saliency(score, [xstensor, metatensor])\n",
    "            axs[i,1].set_title(\" prob(\"+test_dfs[cvnum-1].columns[7+i]+\") = \"+ str(round(predicts[cvnum-1][ff][i]*100,1))+\"%\")\n",
    "            #plt.subplot(row, colums, cnt)\n",
    "            im1 = axs[i,1].imshow(saliency_map[0].reshape(224,224), cmap='jet')\n",
    "            axs[i,1].axis('off')\n",
    "            \n",
    "            #GRADCAM\n",
    "            score = CategoricalScore(i)\n",
    "            cam = gradcam(score, xstensor, penultimate_layer=-1)\n",
    "            axs[i,2].set_title(\" prob(\"+test_dfs[cvnum-1].columns[7+i]+\") = \"+ str(round(predicts[cvnum-1][ff][i]*100,1))+\"%\")\n",
    "            heatmap = np.uint8(cm.jet(cam.reshape(224,224))[..., :3] * 255)\n",
    "            im2 = axs[i,2].imshow(imgs[0].astype('double').reshape(224,224,3) / 2 + 0.5, alpha=0.7)\n",
    "            im2 = axs[i,2].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
    "            axs[i,2].axis('off')\n",
    "            \n",
    "            #plt.colorbar(im0, ax=axs[i,0], orientation='vertical',fraction=0.046, pad=0.04)\n",
    "            #plt.colorbar(im1, ax=axs[i,1], orientation='vertical',fraction=0.046, pad=0.04)\n",
    "            #plt.colorbar(im2, ax=axs[i,2], orientation='vertical',fraction=0.046, pad=0.04)\n",
    "        ##################\n",
    "        #plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir+\"/figs/cv\"+str(cvnum)+\"_\"+test_dfs[cvnum-1].iloc[ff,0].split(\"/\")[3].split(\".\")[0]+\".jpeg\",\n",
    "                   dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir + 'unknown-prob.pickle'.format(cvnum), 'rb') as handle:\n",
    "    unknown_prob = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':22})\n",
    "save_dir = './Results/IIFINAL_class-{}+struct_hn-{}_epochs-{}_lr-{}_{}_3rep/'.format(n_classes, hidden_vgg, n_epochs, lr_coeff, cweights)\n",
    "\n",
    "xs = []\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(save_dir + 'model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(save_dir +\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "for ff in range(len(unknown_df)):\n",
    "    \n",
    "    unknown_dff = pd.DataFrame(unknown_df.iloc[ff,:]).T\n",
    "    unknown_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "    unknown_generator =unknown_datagen.flow_from_dataframe(unknown_dff, x_col='img_path', \n",
    "                                                      y_col=unknown_dff.columns[1:].tolist(),\n",
    "                                                      target_size = (224, 224),\n",
    "                                                      class_mode ='raw',\n",
    "                                                      batch_size = 1,\n",
    "                                                      shuffle = False) \n",
    "\n",
    "    unknown_generator.reset()\n",
    "    data = unknown_generator.next()\n",
    "    imgs = data[0]\n",
    "    meta = data[1][:,:num_struct]\n",
    "    targets = data[1][:,-1*n_classes:]\n",
    "    n_samples = 100\n",
    "\n",
    "\n",
    "    def get_classifier_fn(ximgs):\n",
    "        return loaded_model.predict([ximgs.astype('float32'), meta.astype('float32')])\n",
    "\n",
    "    #test_prob = loaded_model.predict([imgs.astype('float32'), meta.astype('float32')])\n",
    "    #with open(save_dir + 'cv{}_test-prob.pickle'.format(cvnum), 'rb') as handle:\n",
    "    #    test_prob = pickle.load(handle)\n",
    "\n",
    "    fig, axs = plt.subplots(n_classes, 3, figsize = (24,20))\n",
    "    fig.suptitle(\"ID \"+unknown_df.iloc[ff,0].split(\"/\")[2].split(\".\")[0])\n",
    "    #row, colums = n_classes, 3\n",
    "    ################\n",
    "    #LIME\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    #ximgs = imgs[0].astype('double')\n",
    "    explanation = explainer.explain_instance(imgs[0].astype('double'), \n",
    "                                         get_classifier_fn, \n",
    "                                         top_labels=n_classes, \n",
    "                                         hide_color=None,\n",
    "                                         batch_size=1,\n",
    "                                         num_samples=n_samples)\n",
    "\n",
    "    #SALIENCY\n",
    "    replace2linear = ReplaceToLinear()\n",
    "    xstensor = tf.convert_to_tensor(imgs[0], dtype=tf.float32)\n",
    "    metatensor = tf.convert_to_tensor(meta.reshape((1,6)), dtype=tf.float32)\n",
    "    # Create Saliency object.\n",
    "    saliency = Saliency(loaded_model,\n",
    "                        model_modifier=replace2linear,\n",
    "                        clone=True)\n",
    "\n",
    "    #GRADCAM\n",
    "    #create submodel (no meta info)\n",
    "    sub_model = tf.keras.Sequential()\n",
    "    for layer in loaded_model.layers[:20]:\n",
    "        sub_model.add(layer)\n",
    "    example_input_shape = (1, 224, 224, 3)\n",
    "    sub_model.build(example_input_shape)\n",
    "    gradcam = Gradcam(sub_model,\n",
    "              model_modifier=replace2linear,\n",
    "              clone=True)\n",
    "    \n",
    "\n",
    "    for i in range(n_classes):\n",
    "        #LIME\n",
    "        #plt.subplot(row, colums, cnt)\n",
    "        axs[i,0].set_title(\" prob(\"+unknown_df.columns[7+i]+\") = \"+ str(round(unknown_prob[ff][i]*100,1))+\"%\")\n",
    "        temp, mask = explanation.get_image_and_mask(explanation.top_labels[i], \n",
    "                                                    negative_only=False, \n",
    "                                                    positive_only=False, \n",
    "                                                    num_features=10, \n",
    "                                                    hide_rest=False)\n",
    "        axs[i,0].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "        axs[i,0].axis('off')\n",
    "\n",
    "\n",
    "        #SALIENCY\n",
    "        score = CategoricalScore(i)\n",
    "        saliency_map = saliency(score, [xstensor, metatensor])\n",
    "        axs[i,1].set_title(\" prob(\"+unknown_df.columns[7+i]+\") = \"+ str(round(unknown_prob[ff][i]*100,1))+\"%\")\n",
    "        #plt.subplot(row, colums, cnt)\n",
    "        axs[i,1].imshow(saliency_map[0].reshape(224,224), cmap='jet')\n",
    "        #axs[i,1].colorbar();\n",
    "        axs[i,1].axis('off')\n",
    "\n",
    "        #GRADCAM\n",
    "        score = CategoricalScore(i)\n",
    "        cam = gradcam(score, xstensor, penultimate_layer=-1)\n",
    "        axs[i,2].set_title(\" prob(\"+unknown_df.columns[7+i]+\") = \"+ str(round(unknown_prob[ff][i]*100,1))+\"%\")\n",
    "        heatmap = np.uint8(cm.jet(cam.reshape(224,224))[..., :3] * 255)\n",
    "        axs[i,2].imshow(imgs[0].astype('double').reshape(224,224,3) / 2 + 0.5, alpha=0.7)\n",
    "        axs[i,2].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
    "        #axs[i,2].colorbar();\n",
    "        axs[i,2].axis('off')\n",
    "        ##################\n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir+\"/figs/\"+unknown_df.iloc[ff,0].split(\"/\")[2].split(\".\")[0]+\".jpeg\", dpi = 600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
