{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRETRAINED VGG16 FINE TUNED AND RETRAINED ON SEM IMAGES + CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folder data images\n",
    "root_dir = './images/'\n",
    "img_files_paths = list()\n",
    "class_labels = list()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            rel_dir = os.path.relpath(dir_, root_dir)\n",
    "            class_labels.append(rel_dir)\n",
    "            rel_file = os.path.join(rel_dir, file_name)\n",
    "            rel_file = os.path.join(root_dir, rel_file)\n",
    "            img_files_paths.append(rel_file.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read folder data images\n",
    "root_dir1 = './unknown_DB865/'\n",
    "root_dir2 = './unknown_DB866/'\n",
    "img_files_paths_unknown = list()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir1):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            rel_file = os.path.join(root_dir1, file_name)\n",
    "            img_files_paths_unknown.append(rel_file.replace(\"\\\\\", \"/\"))\n",
    "            \n",
    "for dir_, _, files in os.walk(root_dir2):\n",
    "    for file_name in files:\n",
    "        if 'DS_Store' not in file_name:\n",
    "            rel_file = os.path.join(root_dir2, file_name)\n",
    "            img_files_paths_unknown.append(rel_file.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = 'pseudo-vs-all' #  all | pseudo-vs-all | genres\n",
    "\n",
    "if class_type == 'pseudo-vs-all':\n",
    "    class_labels = [l if l == 'pseudoracemus' else 'other' for l in class_labels]\n",
    "elif class_type == 'genres':\n",
    "    class_labels = [l if l != 'pseudoracemus' else 'racemus' for l in class_labels]\n",
    "elif class_type == 'all':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counter = Counter(class_labels).most_common()\n",
    "label_freq = [freq[1] / float(len(class_labels)) for freq in label_counter]\n",
    "label_counter, label_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(img_files_paths)\n",
    "y = np.array(class_labels)\n",
    "train_df = pd.DataFrame([X, y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       rescale=1./255,\n",
    "                                       rotation_range=10,\n",
    "                                       brightness_range=[0.5,1.8],\n",
    "                                       zoom_range=[0.7,1],\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode=\"reflect\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, x_col=0, y_col=1,\n",
    "                                                target_size = (224, 224),\n",
    "                                                batch_size = 1,\n",
    "                                                class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "img = load_img('./4_classes_full/racemus/14052020_B1_A_04.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       rescale=1./255,\n",
    "                                       rotation_range=10,\n",
    "                                       brightness_range=[0.5,1.8],\n",
    "                                       zoom_range=[0.7,1],\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode=\"reflect\")\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # generate batch of images\n",
    "    batch = it.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0].astype('uint8')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Validation + External test: VGG16 IMAGES+CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import structure list and reorder as img_files_paths\n",
    "struct_df = pd.read_csv('./Categories.csv', sep = ';')\n",
    "struct_unknown_df = pd.read_csv('./Categories_unknown.csv', sep = ';')\n",
    "struct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_list = [path.split('/')[-1] for path in img_files_paths]\n",
    "filename_df = pd.DataFrame(file_name_list)\n",
    "filename_df['img_path'] = img_files_paths\n",
    "filename_df['class'] = class_labels\n",
    "filename_df.columns = ['filename', 'img_path', 'class']\n",
    "\n",
    "full_ohe_df = pd.merge(filename_df, struct_df, on='filename')\n",
    "full_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name_list = [path.split('/')[-1] for path in img_files_paths_unknown]\n",
    "filename_df = pd.DataFrame(file_name_list)\n",
    "filename_df['img_path'] = img_files_paths_unknown\n",
    "filename_df.columns = ['filename', 'img_path']\n",
    "\n",
    "full_ohe_df_unknown = pd.merge(filename_df, struct_unknown_df, on='filename')\n",
    "full_ohe_df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(struct_df.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ohe = pd.get_dummies(full_ohe_df['class'])\n",
    "full_ohe_df = pd.concat([full_ohe_df, class_ohe],axis=1)\n",
    "full_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ohe_df = full_ohe_df.drop(columns=['filename', 'trueclass', 'class'])\n",
    "full_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_ohe_df_unknown = full_ohe_df_unknown.drop(columns=['filename', 'trueclass'])\n",
    "full_ohe_df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ PARAMETERS ################\n",
    "\n",
    "hidden_vgg = 128\n",
    "dropout = True\n",
    "\n",
    "lr_coeff = 5\n",
    "learning_rate = 10 / (10 ** lr_coeff)\n",
    "reg = 'l2'\n",
    "\n",
    "k_folds = 4\n",
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "n_steps = 5\n",
    "n_classes = 2\n",
    "num_struct = 6\n",
    "rs = 42\n",
    "num_replica = 2\n",
    "cweights = 'yes' #no\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in list(full_ohe_df.columns[-n_classes:]):\n",
    "    full_ohe_df_unknown[i] = [0]*len(full_ohe_df_unknown)\n",
    "full_ohe_df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = []\n",
    "class_weight = dict()\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_weight[c] = (1 / np.sum(full_ohe_df.iloc[:,-(n_classes-c)].values)) * (len(full_ohe_df) / n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERNAL VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = './Results/FINAL_class-{}+struct_hn-{}_epochs-{}_lr-{}_{}_3rep/'.format(n_classes, hidden_vgg, n_epochs, lr_coeff, cweights)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "test_indices = []\n",
    "unknown_df = full_ohe_df_unknown\n",
    "\n",
    "# Cross-fold validation\n",
    "kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state = rs)\n",
    "kf.get_n_splits(img_files_paths, class_labels)\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(img_files_paths, class_labels):\n",
    "\n",
    "    train_df = full_ohe_df.iloc[train_index]\n",
    "    test_df = full_ohe_df.iloc[test_index]\n",
    "\n",
    "    test_indices.append(test_index)\n",
    "\n",
    "    with open(save_dir + 'cv{}_test_files.pickle'.format(i), 'wb') as handle:\n",
    "        pickle.dump(test_df, handle)\n",
    "\n",
    "    print(\"\\n=========================================\")\n",
    "    print(\"====== K Fold Validation step %d/%d =======\" % (i,k_folds))\n",
    "    print(\"=========================================\\n\")\n",
    "\n",
    "    # Image data generator from dataframe\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       rescale=1./255,\n",
    "                                       rotation_range=10,\n",
    "                                       brightness_range=[0.5,1.8],\n",
    "                                       zoom_range=[0.7,1],\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode=\"reflect\")\n",
    "\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(train_df, x_col='img_path', \n",
    "                                                        y_col=train_df.columns[1:].tolist(),\n",
    "                                                        target_size = (224, 224),\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode = 'raw')\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(test_df, x_col='img_path', \n",
    "                                                      y_col=test_df.columns[1:].tolist(),\n",
    "                                                      target_size = (224, 224),\n",
    "                                                      class_mode ='raw',\n",
    "                                                      batch_size = 1,\n",
    "                                                      shuffle = False) \n",
    "\n",
    "    unknown_generator = test_datagen.flow_from_dataframe(unknown_df, x_col='img_path', \n",
    "                                                      y_col=test_df.columns[1:].tolist(),\n",
    "                                                      target_size = (224, 224),\n",
    "                                                      class_mode ='raw',\n",
    "                                                      batch_size = 1,\n",
    "                                                      shuffle = False) \n",
    "\n",
    "    ############################################################################################################\n",
    "    #create model\n",
    "    model = create_model()\n",
    "\n",
    "    ############################################################################################################\n",
    "\n",
    "    n_training_samples = len(train_generator.filenames)\n",
    "    n_test_samples = len(test_generator.filenames)\n",
    "\n",
    "    if cweights == 'yes':\n",
    "        hist = model.fit_generator(\n",
    "            own_train_generator_func(),\n",
    "            epochs=n_epochs,\n",
    "            validation_data=own_test_generator_func(),\n",
    "            validation_steps=n_test_samples,\n",
    "            steps_per_epoch=n_steps, class_weight=class_weight)\n",
    "    else:\n",
    "            hist = model.fit_generator(\n",
    "            own_train_generator_func(),\n",
    "            epochs=n_epochs,\n",
    "            validation_data=own_test_generator_func(),\n",
    "            validation_steps=n_test_samples,\n",
    "            steps_per_epoch=n_steps)\n",
    "            \n",
    "    model_json = model.to_json()\n",
    "    with open(save_dir + 'cv{}model.json'.format(i), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(save_dir + 'cv{}model.h5'.format(i))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    with open(save_dir + 'cv{}_history.pickle'.format(i), 'wb') as handle:\n",
    "        pickle.dump(hist.history, handle)\n",
    "\n",
    "    test_generator.reset()\n",
    "    test_prob = model.predict_generator(own_test_generator_func(), steps=test_df.shape[0])\n",
    "    with open(save_dir + 'cv{}_test-prob.pickle'.format(i), 'wb') as handle:\n",
    "        pickle.dump(test_prob, handle)\n",
    "\n",
    "    print(\"TEST PROBABILITIES\")\n",
    "    print(test_prob)\n",
    "\n",
    "    unknown_prob = model.predict_generator(own_test_generator_func_unknown(), steps=unknown_df.shape[0])\n",
    "    with open(save_dir + 'cv{}_unknown-prob.pickle'.format(i), 'wb') as handle:\n",
    "        pickle.dump(unknown_prob, handle)\n",
    "\n",
    "    print(\"UNKNOWN PROBABILITIES\")\n",
    "    print(unknown_prob)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTERNAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = full_ohe_df_unknown\n",
    "train_df = full_ohe_df\n",
    "\n",
    "\n",
    "# Image data generator from dataframe\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rescale=1./255,\n",
    "                                   rotation_range=10,\n",
    "                                   brightness_range=[0.5,1.8],\n",
    "                                   zoom_range=[0.7,1],\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"reflect\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, x_col='img_path', \n",
    "                                                    y_col=train_df.columns[1:].tolist(),\n",
    "                                                    target_size = (224, 224),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode = 'raw')\n",
    "\n",
    "unknown_generator = test_datagen.flow_from_dataframe(unknown_df, x_col='img_path', \n",
    "                                                  y_col=unknown_df.columns[1:].tolist(),\n",
    "                                                  target_size = (224, 224),\n",
    "                                                  class_mode ='raw',\n",
    "                                                  batch_size = 1,\n",
    "                                                  shuffle = False) \n",
    "\n",
    "############################################################################################################\n",
    "#create model\n",
    "model = create_model()\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "n_training_samples = len(train_generator.filenames)\n",
    "\n",
    "if cweights == 'yes':\n",
    "    hist = model.fit_generator(\n",
    "        own_train_generator_func(),\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=n_steps, class_weight=class_weight)\n",
    "else:\n",
    "        hist = model.fit_generator(\n",
    "        own_train_generator_func(),\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=n_steps)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(save_dir + 'model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(save_dir + 'model.h5')\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "with open(save_dir + 'history.pickle', 'wb') as handle:\n",
    "    pickle.dump(hist.history, handle)\n",
    "\n",
    "unknown_prob = model.predict_generator(own_test_generator_func_unknown(), steps=unknown_df.shape[0])\n",
    "with open(save_dir + 'unknown-prob.pickle', 'wb') as handle:\n",
    "    pickle.dump(unknown_prob, handle)\n",
    "\n",
    "print(\"UNKNOWN PROBABILITIES\")\n",
    "print(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
